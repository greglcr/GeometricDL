{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Deep Learning on Graph to study Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dgl in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from dgl) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from dgl) (1.14.1)\n",
      "Requirement already satisfied: networkx>=2.1 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from dgl) (3.4.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from dgl) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from dgl) (4.67.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from dgl) (6.1.0)\n",
      "Requirement already satisfied: torchdata>=0.5.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from dgl) (0.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests>=2.19.0->dgl) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests>=2.19.0->dgl) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests>=2.19.0->dgl) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests>=2.19.0->dgl) (2024.8.30)\n",
      "Requirement already satisfied: torch>=2 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torchdata>=0.5.0->dgl) (2.5.1)\n",
      "Requirement already satisfied: filelock in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (3.11.7)\n",
      "Requirement already satisfied: fsspec in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (2024.10.0)\n",
      "Requirement already satisfied: jinja2 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (6.1.0)\n",
      "Requirement already satisfied: pyparsing in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from aiohttp->torch_geometric) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from aiohttp->torch_geometric) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from aiohttp->torch_geometric) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from aiohttp->torch_geometric) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests->torch_geometric) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests->torch_geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests->torch_geometric) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import UPFD\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch.nn.modules import Linear\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.functional import F\n",
    "import torch\n",
    "import argparse\n",
    "import os.path as osp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is initialized there. Note that:\n",
    "- `feature` can be `content` (raw content of the tweet), `bert` (content transformed by a transformer), `profile` (user profile info such as number of tweets, followers, and join date), `spacy` (content transformed by a simple NLP model)\n",
    "- `dataset` is either `politifact` or `gossipcop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5464\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import UPFD\n",
    "import os.path as osp\n",
    "import torch\n",
    "\n",
    "# Paths and settings\n",
    "_file_ = '..'\n",
    "file = _file_\n",
    "dataset = 'gossipcop'  # or 'politifact'\n",
    "path = osp.join(osp.dirname(osp.realpath(file)), '..', 'data', 'UPFD')\n",
    "\n",
    "# Load datasets with bert and profile features separately\n",
    "train_dataset_bert = UPFD(path, dataset, 'bert', 'train')\n",
    "train_dataset_profile = UPFD(path, dataset, 'profile', 'train')\n",
    "\n",
    "val_dataset_bert = UPFD(path, dataset, 'bert', 'val')\n",
    "val_dataset_profile = UPFD(path, dataset, 'profile', 'val')\n",
    "\n",
    "test_dataset_bert = UPFD(path, dataset, 'bert', 'test')\n",
    "test_dataset_profile = UPFD(path, dataset, 'profile', 'test')\n",
    "\n",
    "# Check that both datasets are aligned\n",
    "assert len(train_dataset_bert) == len(train_dataset_profile)\n",
    "assert len(val_dataset_bert) == len(val_dataset_profile)\n",
    "assert len(test_dataset_bert) == len(test_dataset_profile)\n",
    "\n",
    "# Function to combine features\n",
    "def combine_features(dataset_bert, dataset_profile):\n",
    "    combined_data = []\n",
    "    for data_bert, data_profile in zip(dataset_bert, dataset_profile):\n",
    "        data_bert.x = torch.cat([data_bert.x, data_profile.x], dim=-1)  # Concatenate features\n",
    "        combined_data.append(data_bert)\n",
    "    return combined_data\n",
    "\n",
    "# Combine features for train, val, and test datasets\n",
    "train_dataset = combine_features(train_dataset_bert, train_dataset_profile)\n",
    "val_dataset = combine_features(val_dataset_bert, val_dataset_profile)\n",
    "test_dataset = combine_features(test_dataset_bert, test_dataset_profile)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "print(len(train_dataset) + len(val_dataset) + len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels,\n",
    "                 concat=False):\n",
    "        super().__init__()\n",
    "        self.concat = concat\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.max_pooling = global_mean_pool # They use Max_pool in the article but that doesn't work pretty well.\n",
    "        self.lin1 = Linear(hidden_channels, 2 * hidden_channels)\n",
    "        self.lin2 = Linear(2*hidden_channels,2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        #print(f\"Après 1ere couche: {x.shape}\")\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        #print(f\"Après 2eme couche: {x.shape}\")\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.max_pooling(x, batch)\n",
    "        #print(f\"Après 3eme couche: {x.shape}\")\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.lin1(x)\n",
    "        #print(f\"Après 4eme couche: {x.shape}\")\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.lin2(x)\n",
    "        #print(f\"Après 5eme couche: {x.shape}\")\n",
    "        return x.softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(778, 128,2, concat=True).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4858785642809047"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = total_examples = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data.x, data.edge_index, data.batch).argmax(dim=-1)\n",
    "        total_correct += int((pred ==\n",
    "         data.y).sum())\n",
    "        total_examples += data.num_graphs\n",
    "\n",
    "    return total_correct / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: -0.4900, Train: 0.4899, Val: 0.5147, Test: 0.5008\n",
      "Epoch: 02, Loss: -0.4862, Train: 0.4899, Val: 0.5147, Test: 0.5008\n",
      "Epoch: 03, Loss: -0.5095, Train: 0.6310, Val: 0.6447, Test: 0.6388\n",
      "Epoch: 04, Loss: -0.6253, Train: 0.6090, Val: 0.6154, Test: 0.6066\n",
      "Epoch: 05, Loss: -0.6984, Train: 0.7445, Val: 0.7418, Test: 0.7162\n",
      "Epoch: 06, Loss: -0.7333, Train: 0.7454, Val: 0.7216, Test: 0.7073\n",
      "Epoch: 07, Loss: -0.7419, Train: 0.7637, Val: 0.7363, Test: 0.7201\n",
      "Epoch: 08, Loss: -0.7722, Train: 0.8004, Val: 0.7601, Test: 0.7520\n",
      "Epoch: 09, Loss: -0.7600, Train: 0.6822, Val: 0.6813, Test: 0.6683\n",
      "Epoch: 10, Loss: -0.6970, Train: 0.7582, Val: 0.7418, Test: 0.7227\n",
      "Epoch: 11, Loss: -0.7238, Train: 0.7866, Val: 0.7656, Test: 0.7470\n",
      "Epoch: 12, Loss: -0.7583, Train: 0.7317, Val: 0.7051, Test: 0.7049\n",
      "Epoch: 13, Loss: -0.7571, Train: 0.7225, Val: 0.7033, Test: 0.6942\n",
      "Epoch: 14, Loss: -0.7213, Train: 0.7509, Val: 0.7234, Test: 0.7185\n",
      "Epoch: 15, Loss: -0.7827, Train: 0.7940, Val: 0.7711, Test: 0.7556\n",
      "Epoch: 16, Loss: -0.7792, Train: 0.8068, Val: 0.7711, Test: 0.7541\n",
      "Epoch: 17, Loss: -0.8003, Train: 0.8187, Val: 0.7821, Test: 0.7710\n",
      "Epoch: 18, Loss: -0.7988, Train: 0.8233, Val: 0.7729, Test: 0.7750\n",
      "Epoch: 19, Loss: -0.7448, Train: 0.7381, Val: 0.7179, Test: 0.6952\n",
      "Epoch: 20, Loss: -0.7929, Train: 0.8260, Val: 0.7692, Test: 0.7569\n",
      "Epoch: 21, Loss: -0.7275, Train: 0.7637, Val: 0.7436, Test: 0.7295\n",
      "Epoch: 22, Loss: -0.7526, Train: 0.8159, Val: 0.7747, Test: 0.7593\n",
      "Epoch: 23, Loss: -0.7465, Train: 0.7940, Val: 0.7582, Test: 0.7517\n",
      "Epoch: 24, Loss: -0.7798, Train: 0.7143, Val: 0.7033, Test: 0.6895\n",
      "Epoch: 25, Loss: -0.7590, Train: 0.7793, Val: 0.7692, Test: 0.7386\n",
      "Epoch: 26, Loss: -0.7801, Train: 0.8022, Val: 0.7582, Test: 0.7561\n",
      "Epoch: 27, Loss: -0.7600, Train: 0.8150, Val: 0.7821, Test: 0.7601\n",
      "Epoch: 28, Loss: -0.7982, Train: 0.8269, Val: 0.7857, Test: 0.7640\n",
      "Epoch: 29, Loss: -0.8167, Train: 0.8196, Val: 0.7839, Test: 0.7679\n",
      "Epoch: 30, Loss: -0.8147, Train: 0.8397, Val: 0.7930, Test: 0.7731\n",
      "Epoch: 31, Loss: -0.8065, Train: 0.7839, Val: 0.7527, Test: 0.7334\n",
      "Epoch: 32, Loss: -0.7981, Train: 0.8452, Val: 0.7766, Test: 0.7755\n",
      "Epoch: 33, Loss: -0.8206, Train: 0.8379, Val: 0.7912, Test: 0.7791\n",
      "Epoch: 34, Loss: -0.8399, Train: 0.8626, Val: 0.7949, Test: 0.7849\n",
      "Epoch: 35, Loss: -0.8129, Train: 0.8590, Val: 0.7894, Test: 0.7781\n",
      "Epoch: 36, Loss: -0.7887, Train: 0.6584, Val: 0.6410, Test: 0.6249\n",
      "Epoch: 37, Loss: -0.7604, Train: 0.8342, Val: 0.7674, Test: 0.7784\n",
      "Epoch: 38, Loss: -0.7666, Train: 0.8297, Val: 0.7619, Test: 0.7721\n",
      "Epoch: 39, Loss: -0.7685, Train: 0.7967, Val: 0.7564, Test: 0.7533\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[189], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m test(train_loader)\n\u001b[1;32m      4\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m test(val_loader)\n\u001b[0;32m----> 5\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Ulm/M1/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[188], line 7\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m      5\u001b[0m total_correct \u001b[38;5;241m=\u001b[39m total_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m----> 7\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39mbatch)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m     total_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((pred \u001b[38;5;241m==\u001b[39m\n\u001b[1;32m     10\u001b[0m      data\u001b[38;5;241m.\u001b[39my)\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[0;32m~/Ulm/M1/.venv/lib/python3.12/site-packages/torch_geometric/data/data.py:362\u001b[0m, in \u001b[0;36mBaseData.to\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    358\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Ulm/M1/.venv/lib/python3.12/site-packages/torch_geometric/data/data.py:342\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[0;32m--> 342\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Ulm/M1/.venv/lib/python3.12/site-packages/torch_geometric/data/storage.py:201\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Ulm/M1/.venv/lib/python3.12/site-packages/torch_geometric/data/storage.py:897\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m--> 897\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[1;32m    899\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[0;32m~/Ulm/M1/.venv/lib/python3.12/site-packages/torch_geometric/data/data.py:363\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    358\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m--> 363\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 200):\n",
    "    loss = train()\n",
    "    train_acc = test(train_loader)\n",
    "    val_acc = test(val_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, 'f'Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
