{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Deep Learning on Graph to study Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dgl\n",
      "  Using cached dgl-2.1.0-cp312-cp312-manylinux1_x86_64.whl.metadata (553 bytes)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from dgl) (2.1.3)\n",
      "Collecting scipy>=1.1.0 (from dgl)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting networkx>=2.1 (from dgl)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting requests>=2.19.0 (from dgl)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from dgl)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from dgl) (6.1.0)\n",
      "Collecting torchdata>=0.5.0 (from dgl)\n",
      "  Using cached torchdata-0.9.0-cp312-cp312-manylinux1_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.19.0->dgl)\n",
      "  Using cached charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.19.0->dgl)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.19.0->dgl)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.19.0->dgl)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting torch>=2 (from torchdata>=0.5.0->dgl)\n",
      "  Using cached torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting filelock (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jinja2 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting setuptools (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Using cached dgl-2.1.0-cp312-cp312-manylinux1_x86_64.whl (8.6 MB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.8 MB)\n",
      "Using cached torchdata-0.9.0-cp312-cp312-manylinux1_x86_64.whl (2.7 MB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, urllib3, typing-extensions, tqdm, sympy, setuptools, scipy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, triton, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchdata, dgl\n",
      "Successfully installed MarkupSafe-3.0.2 certifi-2024.8.30 charset-normalizer-3.4.0 dgl-2.1.0 filelock-3.16.1 fsspec-2024.10.0 idna-3.10 jinja2-3.1.4 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 requests-2.32.3 scipy-1.14.1 setuptools-75.6.0 sympy-1.13.1 torch-2.5.1 torchdata-0.9.0 tqdm-4.67.1 triton-3.1.0 typing-extensions-4.12.2 urllib3-2.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting aiohttp (from torch_geometric)\n",
      "  Downloading aiohttp-3.11.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: fsspec in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (2024.10.0)\n",
      "Requirement already satisfied: jinja2 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (6.1.0)\n",
      "Requirement already satisfied: pyparsing in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (4.67.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch_geometric)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->torch_geometric)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->torch_geometric)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->torch_geometric)\n",
      "  Downloading propcache-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch_geometric)\n",
      "  Downloading yarl-1.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests->torch_geometric) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests->torch_geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests->torch_geometric) (2024.8.30)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Downloading propcache-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (248 kB)\n",
      "Downloading yarl-1.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
      "Installing collected packages: propcache, multidict, frozenlist, attrs, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch_geometric\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.11.7 aiosignal-1.3.1 attrs-24.2.0 frozenlist-1.5.0 multidict-6.1.0 propcache-0.2.0 torch_geometric-2.6.1 yarl-1.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import UPFD\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_max_pool\n",
    "from torch.nn.modules import Linear\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.functional import F\n",
    "import torch\n",
    "import argparse\n",
    "import os.path as osp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is initialized there. Note that:\n",
    "- `feature` can be `content` (raw content of the tweet), `bert` (content transformed by a transformer), `profile` (user profile info such as number of tweets, followers, and join date), `spacy` (content transformed by a simple NLP model)\n",
    "- `dataset` is either `politifact` or `gossipcop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://drive.usercontent.google.com/download?id=1VskhAQ92PrT4sWEKQ2v2-AJhEcpp4A81&confirm=t\n",
      "Extracting /home/crvr/Ulm/data/UPFD/gossipcop/raw/data.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5464\n"
     ]
    }
   ],
   "source": [
    "file = '..'\n",
    "\n",
    "dataset = 'gossipcop'#'politifact'\n",
    "feature = 'spacy'\n",
    "model = 'GCN'\n",
    "\n",
    "path = osp.join(osp.dirname(osp.realpath(file)), '..', 'data', 'UPFD')\n",
    "train_dataset = UPFD(path, dataset, feature, 'train')\n",
    "val_dataset = UPFD(path, dataset, feature, 'val')\n",
    "test_dataset = UPFD(path, dataset, feature, 'test')\n",
    "\n",
    "print(len(train_dataset) + len(val_dataset) + len(test_dataset))\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels,\n",
    "                 concat=False):\n",
    "        super().__init__()\n",
    "        self.concat = concat\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.lin0 = Linear(in_channels, hidden_channels)\n",
    "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        h = self.conv1(x, edge_index).relu()\n",
    "        h = global_max_pool(h, batch)\n",
    "        if self.concat:\n",
    "            # Get the root node (tweet) features of each graph:\n",
    "            root = (batch[1:] - batch[:-1]).nonzero(as_tuple=False).view(-1)\n",
    "            root = torch.cat([root.new_zeros(1), root + 1], dim=0)\n",
    "            news = x[root]\n",
    "            news = self.lin0(news).relu()\n",
    "            h = self.lin1(torch.cat([news, h], dim=-1)).relu()\n",
    "        h = self.lin2(h)\n",
    "        return h.log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(train_dataset.num_features, 128,\n",
    "            train_dataset.num_classes, concat=True).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6882300553741035"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = total_examples = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data.x, data.edge_index, data.batch).argmax(dim=-1)\n",
    "        total_correct += int((pred == data.y).sum())\n",
    "        total_examples += data.num_graphs\n",
    "\n",
    "    return total_correct / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 0.6811, Train: 0.7766, Val: 0.8059, Test: 0.7878\n",
      "Epoch: 02, Loss: 0.6739, Train: 0.6612, Val: 0.6502, Test: 0.6398\n",
      "Epoch: 03, Loss: 0.6494, Train: 0.8068, Val: 0.8370, Test: 0.8092\n",
      "Epoch: 04, Loss: 0.6045, Train: 0.8571, Val: 0.8645, Test: 0.8544\n",
      "Epoch: 05, Loss: 0.5239, Train: 0.8718, Val: 0.8919, Test: 0.8756\n",
      "Epoch: 06, Loss: 0.4105, Train: 0.9002, Val: 0.9194, Test: 0.8999\n",
      "Epoch: 07, Loss: 0.3053, Train: 0.9185, Val: 0.9286, Test: 0.9187\n",
      "Epoch: 08, Loss: 0.2522, Train: 0.9240, Val: 0.9322, Test: 0.9205\n",
      "Epoch: 09, Loss: 0.2342, Train: 0.9185, Val: 0.9231, Test: 0.9166\n",
      "Epoch: 10, Loss: 0.2206, Train: 0.9203, Val: 0.9231, Test: 0.9179\n",
      "Epoch: 11, Loss: 0.2294, Train: 0.9359, Val: 0.9414, Test: 0.9341\n",
      "Epoch: 12, Loss: 0.2154, Train: 0.9386, Val: 0.9432, Test: 0.9362\n",
      "Epoch: 13, Loss: 0.2043, Train: 0.9423, Val: 0.9487, Test: 0.9357\n",
      "Epoch: 14, Loss: 0.2040, Train: 0.9405, Val: 0.9414, Test: 0.9360\n",
      "Epoch: 15, Loss: 0.1959, Train: 0.9451, Val: 0.9469, Test: 0.9381\n",
      "Epoch: 16, Loss: 0.1984, Train: 0.9460, Val: 0.9487, Test: 0.9391\n",
      "Epoch: 17, Loss: 0.1880, Train: 0.9478, Val: 0.9469, Test: 0.9391\n",
      "Epoch: 18, Loss: 0.1877, Train: 0.9451, Val: 0.9505, Test: 0.9373\n",
      "Epoch: 19, Loss: 0.1897, Train: 0.9414, Val: 0.9505, Test: 0.9347\n",
      "Epoch: 20, Loss: 0.1884, Train: 0.9405, Val: 0.9524, Test: 0.9341\n",
      "Epoch: 21, Loss: 0.1913, Train: 0.9341, Val: 0.9451, Test: 0.9289\n",
      "Epoch: 22, Loss: 0.1916, Train: 0.9368, Val: 0.9505, Test: 0.9294\n",
      "Epoch: 23, Loss: 0.1853, Train: 0.9524, Val: 0.9542, Test: 0.9428\n",
      "Epoch: 24, Loss: 0.1692, Train: 0.9469, Val: 0.9396, Test: 0.9420\n",
      "Epoch: 25, Loss: 0.1697, Train: 0.9487, Val: 0.9469, Test: 0.9430\n",
      "Epoch: 26, Loss: 0.1730, Train: 0.9478, Val: 0.9451, Test: 0.9433\n",
      "Epoch: 27, Loss: 0.1639, Train: 0.9533, Val: 0.9505, Test: 0.9462\n",
      "Epoch: 28, Loss: 0.1610, Train: 0.9487, Val: 0.9560, Test: 0.9378\n",
      "Epoch: 29, Loss: 0.1613, Train: 0.9560, Val: 0.9524, Test: 0.9472\n",
      "Epoch: 30, Loss: 0.1589, Train: 0.9496, Val: 0.9579, Test: 0.9394\n",
      "Epoch: 31, Loss: 0.1610, Train: 0.9560, Val: 0.9524, Test: 0.9464\n",
      "Epoch: 32, Loss: 0.1563, Train: 0.9551, Val: 0.9524, Test: 0.9498\n",
      "Epoch: 33, Loss: 0.1543, Train: 0.9478, Val: 0.9377, Test: 0.9415\n",
      "Epoch: 34, Loss: 0.1556, Train: 0.9524, Val: 0.9487, Test: 0.9475\n",
      "Epoch: 35, Loss: 0.1498, Train: 0.9515, Val: 0.9505, Test: 0.9472\n",
      "Epoch: 36, Loss: 0.1518, Train: 0.9515, Val: 0.9505, Test: 0.9477\n",
      "Epoch: 37, Loss: 0.1479, Train: 0.9515, Val: 0.9487, Test: 0.9475\n",
      "Epoch: 38, Loss: 0.1440, Train: 0.9597, Val: 0.9505, Test: 0.9496\n",
      "Epoch: 39, Loss: 0.1416, Train: 0.9625, Val: 0.9560, Test: 0.9490\n",
      "Epoch: 40, Loss: 0.1443, Train: 0.9570, Val: 0.9524, Test: 0.9506\n",
      "Epoch: 41, Loss: 0.1441, Train: 0.9551, Val: 0.9505, Test: 0.9482\n",
      "Epoch: 42, Loss: 0.1414, Train: 0.9579, Val: 0.9560, Test: 0.9514\n",
      "Epoch: 43, Loss: 0.1367, Train: 0.9652, Val: 0.9579, Test: 0.9493\n",
      "Epoch: 44, Loss: 0.1370, Train: 0.9652, Val: 0.9487, Test: 0.9516\n",
      "Epoch: 45, Loss: 0.1391, Train: 0.9643, Val: 0.9634, Test: 0.9451\n",
      "Epoch: 46, Loss: 0.1392, Train: 0.9588, Val: 0.9560, Test: 0.9530\n",
      "Epoch: 47, Loss: 0.1343, Train: 0.9570, Val: 0.9524, Test: 0.9396\n",
      "Epoch: 48, Loss: 0.1416, Train: 0.9597, Val: 0.9579, Test: 0.9417\n",
      "Epoch: 49, Loss: 0.1385, Train: 0.9615, Val: 0.9505, Test: 0.9519\n",
      "Epoch: 50, Loss: 0.1310, Train: 0.9661, Val: 0.9579, Test: 0.9506\n",
      "Epoch: 51, Loss: 0.1282, Train: 0.9597, Val: 0.9560, Test: 0.9543\n",
      "Epoch: 52, Loss: 0.1268, Train: 0.9625, Val: 0.9560, Test: 0.9540\n",
      "Epoch: 53, Loss: 0.1245, Train: 0.9652, Val: 0.9542, Test: 0.9548\n",
      "Epoch: 54, Loss: 0.1256, Train: 0.9606, Val: 0.9542, Test: 0.9425\n",
      "Epoch: 55, Loss: 0.1473, Train: 0.9634, Val: 0.9579, Test: 0.9530\n",
      "Epoch: 56, Loss: 0.1322, Train: 0.9652, Val: 0.9560, Test: 0.9545\n",
      "Epoch: 57, Loss: 0.1226, Train: 0.9643, Val: 0.9560, Test: 0.9561\n",
      "Epoch: 58, Loss: 0.1218, Train: 0.9661, Val: 0.9579, Test: 0.9548\n",
      "Epoch: 59, Loss: 0.1215, Train: 0.9679, Val: 0.9615, Test: 0.9524\n",
      "Epoch: 60, Loss: 0.1204, Train: 0.9670, Val: 0.9560, Test: 0.9548\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 61):\n",
    "    loss = train()\n",
    "    train_acc = test(train_loader)\n",
    "    val_acc = test(val_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, 'f'Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
