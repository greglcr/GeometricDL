{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Deep Learning on Graph to study Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dgl\n",
      "  Using cached dgl-2.1.0-cp312-cp312-manylinux1_x86_64.whl.metadata (553 bytes)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from dgl) (2.1.3)\n",
      "Collecting scipy>=1.1.0 (from dgl)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting networkx>=2.1 (from dgl)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting requests>=2.19.0 (from dgl)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from dgl)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from dgl) (6.1.0)\n",
      "Collecting torchdata>=0.5.0 (from dgl)\n",
      "  Using cached torchdata-0.9.0-cp312-cp312-manylinux1_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.19.0->dgl)\n",
      "  Using cached charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.19.0->dgl)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.19.0->dgl)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.19.0->dgl)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting torch>=2 (from torchdata>=0.5.0->dgl)\n",
      "  Using cached torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting filelock (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jinja2 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting setuptools (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Using cached dgl-2.1.0-cp312-cp312-manylinux1_x86_64.whl (8.6 MB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.8 MB)\n",
      "Using cached torchdata-0.9.0-cp312-cp312-manylinux1_x86_64.whl (2.7 MB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, urllib3, typing-extensions, tqdm, sympy, setuptools, scipy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, triton, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchdata, dgl\n",
      "Successfully installed MarkupSafe-3.0.2 certifi-2024.8.30 charset-normalizer-3.4.0 dgl-2.1.0 filelock-3.16.1 fsspec-2024.10.0 idna-3.10 jinja2-3.1.4 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 requests-2.32.3 scipy-1.14.1 setuptools-75.6.0 sympy-1.13.1 torch-2.5.1 torchdata-0.9.0 tqdm-4.67.1 triton-3.1.0 typing-extensions-4.12.2 urllib3-2.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting aiohttp (from torch_geometric)\n",
      "  Downloading aiohttp-3.11.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: fsspec in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (2024.10.0)\n",
      "Requirement already satisfied: jinja2 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (6.1.0)\n",
      "Requirement already satisfied: pyparsing in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from torch_geometric) (4.67.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch_geometric)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->torch_geometric)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->torch_geometric)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->torch_geometric)\n",
      "  Downloading propcache-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch_geometric)\n",
      "  Downloading yarl-1.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests->torch_geometric) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests->torch_geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/crvr/Ulm/M1/.venv/lib/python3.12/site-packages (from requests->torch_geometric) (2024.8.30)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Downloading propcache-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (248 kB)\n",
      "Downloading yarl-1.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
      "Installing collected packages: propcache, multidict, frozenlist, attrs, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch_geometric\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.11.7 aiosignal-1.3.1 attrs-24.2.0 frozenlist-1.5.0 multidict-6.1.0 propcache-0.2.0 torch_geometric-2.6.1 yarl-1.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import UPFD\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch.nn.modules import Linear\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.functional import F\n",
    "import torch\n",
    "import argparse\n",
    "import os.path as osp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is initialized there. Note that:\n",
    "- `feature` can be `content` (raw content of the tweet), `bert` (content transformed by a transformer), `profile` (user profile info such as number of tweets, followers, and join date), `spacy` (content transformed by a simple NLP model)\n",
    "- `dataset` is either `politifact` or `gossipcop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5464\n"
     ]
    }
   ],
   "source": [
    "file = '..'\n",
    "\n",
    "dataset = 'gossipcop'#'politifact'\n",
    "feature = 'bert'\n",
    "model = 'GCN'\n",
    "\n",
    "path = osp.join(osp.dirname(osp.realpath(file)), '..', 'data', 'UPFD')\n",
    "train_dataset = UPFD(path, dataset, feature, 'train')\n",
    "val_dataset = UPFD(path, dataset, feature, 'val')\n",
    "test_dataset = UPFD(path, dataset, feature, 'test')\n",
    "\n",
    "print(len(train_dataset) + len(val_dataset) + len(test_dataset))\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels,\n",
    "                 concat=False):\n",
    "        super().__init__()\n",
    "        self.concat = concat\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.mean_pooling = global_mean_pool # They use Max_pool in the article but that doesn't work pretty well.\n",
    "        self.lin1 = Linear(hidden_channels, 2 * hidden_channels)\n",
    "        self.lin2 = Linear(2*hidden_channels,2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        #print(f\"Après 1ere couche: {x.shape}\")\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        #print(f\"Après 2eme couche: {x.shape}\")\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.mean_pooling(x, batch)\n",
    "        #print(f\"Après 3eme couche: {x.shape}\")\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.lin1(x)\n",
    "        #print(f\"Après 4eme couche: {x.shape}\")\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.lin2(x)\n",
    "        #print(f\"Après 5eme couche: {x.shape}\")\n",
    "        return x.log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(train_dataset.num_features, 128,\n",
    "            train_dataset.num_classes, concat=True).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3816660378442143"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = total_examples = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data.x, data.edge_index, data.batch).argmax(dim=-1)\n",
    "        total_correct += int((pred ==\n",
    "         data.y).sum())\n",
    "        total_examples += data.num_graphs\n",
    "\n",
    "    return total_correct / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 0.7167, Train: 0.5183, Val: 0.4908, Test: 0.5086\n",
      "Epoch: 02, Loss: 0.6242, Train: 0.7280, Val: 0.7381, Test: 0.7222\n",
      "Epoch: 03, Loss: 0.5364, Train: 0.7262, Val: 0.7271, Test: 0.7138\n",
      "Epoch: 04, Loss: 0.5321, Train: 0.7756, Val: 0.7784, Test: 0.7493\n",
      "Epoch: 05, Loss: 0.5165, Train: 0.7253, Val: 0.7271, Test: 0.7023\n",
      "Epoch: 06, Loss: 0.4650, Train: 0.8059, Val: 0.7930, Test: 0.7595\n",
      "Epoch: 07, Loss: 0.4498, Train: 0.7344, Val: 0.7106, Test: 0.6997\n",
      "Epoch: 08, Loss: 0.4492, Train: 0.7811, Val: 0.7637, Test: 0.7457\n",
      "Epoch: 09, Loss: 0.4153, Train: 0.8013, Val: 0.7619, Test: 0.7475\n",
      "Epoch: 10, Loss: 0.4232, Train: 0.7830, Val: 0.7454, Test: 0.7344\n",
      "Epoch: 11, Loss: 0.3780, Train: 0.8471, Val: 0.7857, Test: 0.7778\n",
      "Epoch: 12, Loss: 0.3313, Train: 0.8581, Val: 0.7967, Test: 0.7778\n",
      "Epoch: 13, Loss: 0.3319, Train: 0.8416, Val: 0.7967, Test: 0.7640\n",
      "Epoch: 14, Loss: 0.3701, Train: 0.8700, Val: 0.7747, Test: 0.7781\n",
      "Epoch: 15, Loss: 0.3155, Train: 0.8864, Val: 0.7821, Test: 0.7880\n",
      "Epoch: 16, Loss: 0.2767, Train: 0.8361, Val: 0.7582, Test: 0.7569\n",
      "Epoch: 17, Loss: 0.2724, Train: 0.8755, Val: 0.7637, Test: 0.7737\n",
      "Epoch: 18, Loss: 0.3469, Train: 0.8782, Val: 0.8004, Test: 0.7776\n",
      "Epoch: 19, Loss: 0.3073, Train: 0.8700, Val: 0.7802, Test: 0.7760\n",
      "Epoch: 20, Loss: 0.2680, Train: 0.9048, Val: 0.7985, Test: 0.7925\n",
      "Epoch: 21, Loss: 0.2375, Train: 0.9057, Val: 0.7949, Test: 0.7899\n",
      "Epoch: 22, Loss: 0.2787, Train: 0.8553, Val: 0.7857, Test: 0.7504\n",
      "Epoch: 23, Loss: 0.2327, Train: 0.9048, Val: 0.7692, Test: 0.7906\n",
      "Epoch: 24, Loss: 0.2372, Train: 0.8709, Val: 0.7802, Test: 0.7588\n",
      "Epoch: 25, Loss: 0.2798, Train: 0.9112, Val: 0.7912, Test: 0.7872\n",
      "Epoch: 26, Loss: 0.2256, Train: 0.9048, Val: 0.7674, Test: 0.7870\n",
      "Epoch: 27, Loss: 0.1946, Train: 0.9295, Val: 0.7967, Test: 0.7849\n",
      "Epoch: 28, Loss: 0.3223, Train: 0.9093, Val: 0.7747, Test: 0.7823\n",
      "Epoch: 29, Loss: 0.3094, Train: 0.8397, Val: 0.7546, Test: 0.7546\n",
      "Epoch: 30, Loss: 0.2427, Train: 0.9130, Val: 0.8059, Test: 0.7886\n",
      "Epoch: 31, Loss: 0.1973, Train: 0.9231, Val: 0.7967, Test: 0.7914\n",
      "Epoch: 32, Loss: 0.1737, Train: 0.9332, Val: 0.7766, Test: 0.7946\n",
      "Epoch: 33, Loss: 0.1590, Train: 0.9277, Val: 0.7949, Test: 0.7844\n",
      "Epoch: 34, Loss: 0.2819, Train: 0.7665, Val: 0.6740, Test: 0.6869\n",
      "Epoch: 35, Loss: 0.4040, Train: 0.8159, Val: 0.7399, Test: 0.7337\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 200):\n",
    "    loss = train()\n",
    "    train_acc = test(train_loader)\n",
    "    val_acc = test(val_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, 'f'Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
